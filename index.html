<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Aniket Didolkar</title>
  <meta name="author" content="Aniket Didolkar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" type="image/png" href="images/favicon.png">
  <link rel="shortcut icon" type="image/png" href="images/favicon.png">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap" rel="stylesheet">
</head>

<body>
  <div class="container">
    <div class="header">
      <div class="profile-section">
        <div class="profile-info">
          <h1>Aniket Didolkar</h1>
          <p class="intro">I am a Ph.D. student at <a href="https://mila.quebec/" target="_blank">Mila</a> and <a href="https://www.umontreal.ca/en/" target="_blank">The University of Montreal</a>, advised by <a href="https://yoshuabengio.org/" target="_blank">Prof. Yoshua Bengio</a>, <a href="https://anirudh9119.github.io/" target="_blank">Dr. Anirudh Goyal</a>, and <a href="https://home.cs.colorado.edu/~mozer/index.php" target="_blank">Prof. Michael Mozer</a>. I am also a visiting researcher at <a href="https://ai.facebook.com/" target="_blank">Meta</a>, where I work with <a href="https://scholar.google.com/citations?user=ZWCcHYwAAAAJ" target="_blank">Dr. Nicolas Ballas</a>.</p>
<p class="research">My research is rooted in building cognitive science-inspired deep learning techniques. Broadly, I am interested in designing models that learn and reason like humans. Most recently, I have been exploring the metacognitive abilities of large language models (LLMs) in the context of mathematical problem solving (<a href="https://arxiv.org/abs/2405.12205" target="_blank">1</a>). In earlier work, I developed hybrid architectures that integrate recurrent networks with transformers to effectively handle long-context modeling (<a href="https://arxiv.org/abs/2205.14794" target="_blank">2</a>). Another major thread of my Ph.D. has focused on object-centric learning, where I have worked on building general-purpose visual representations that capture compositional structure and enable downstream reasoning (<a href="https://arxiv.org/abs/2306.02204" target="_blank">3</a>, <a href="https://openreview.net/forum?id=bSq0XGS3kW" target="_blank">4</a>, <a href="https://arxiv.org/abs/2503.21747" target="_blank">5</a>).</p>
<p class="future">Going forward, I am particularly interested in:</p>
<ul>
<li><strong>Equipping LLMs with good thinking frameworks:</strong> While reinforcement learning has dramatically improved LLM reasoning, there remains a gap in how these models acquire and reuse knowledge. I am excited by the possibility of enabling LLMs to convert past reasoning traces into procedural habits, and to adopt structured thinking frameworks that maximize the utility of their context window.</li>
<li><strong>Multi-agent collaboration:</strong> Much of human progress comes from collaboration. To use LLMs to unlock progress on challenging scientific endeavors it would be crucial to develop frameworks which allow various LLM agents to collaborate with each other in a scalable manner as opposed to one LLM thinking for an extremely long time.</li>
</ul>
<br>
<p class="experience-brief">
  Prior to my current role, I gained valuable research experience across academia and industry through several internships. I was a research intern at 
  <a href="https://www.valencelabs.com/" target="_blank">Valence Labs</a>, where I worked with 
  <a href="https://jhartford.github.io/" target="_blank">Dr. Jason Hartford</a> on experimental design strategies for estimating the effects of gene knockouts in cells. 
  Before that, I interned at <a href="https://www.microsoft.com/en-us/research/" target="_blank">Microsoft Research NYC</a> with 
  <a href="https://scholar.google.ca/citations?user=BFzFy1YAAAAJ&hl=en" target="_blank">Dr. Alex Lamb</a> on reinforcement learning. 
  Prior to starting my Ph.D., I spent a year at <a href="https://mila.quebec/en/" target="_blank">Mila</a> working with 
  <a href="https://anirudh9119.github.io/" target="_blank">Dr. Anirudh Goyal</a> and 
  <a href="https://yoshuabengio.org/" target="_blank">Prof. Yoshua Bengio</a> on cognitive science-inspired deep learning projects, now published at NeurIPS 2021 and ICLR 2022. 
  During my undergraduate studies, I was a Google Summer of Code student developer with Preferred Networks, where I contributed CUDA-optimized implementations of RNNs, GRUs, and LSTMs to the 
  <a href="https://docs.chainer.org/en/stable/chainerx/tutorial/" target="_blank">ChainerX</a> deep learning library. 
  I also collaborated with <a href="http://midas.iiitd.edu.in/team/rajiv-ratn-shah.html" target="_blank">Prof. Rajiv Ratn Shah</a> at IIIT Delhi on applied NLP projects, and with 
  <a href="https://ece.iisc.ac.in/~aditya/index.html" target="_blank">Prof. Aditya Gopalan</a> at IISc Bangalore on time-series forecasting models for urban pollution.
</p>
        </div>
        <div class="profile-photo">
          <img src="images/ava-modified.jpg" alt="Aniket Didolkar" class="profile-img">
        </div>
      </div>
      
      <div class="social-links">
        <a target="_blank" href="data/Aniket_Didolkar_CV.pdf" class="social-link">CV</a>
        <span class="separator">•</span>
        <a target="_blank" href="mailto:adidolkar123@gmail.com" class="social-link">Email</a>
        <span class="separator">•</span>
        <a target="_blank" href="https://scholar.google.com/citations?user=ekvl5o0AAAAJ&hl=en" class="social-link">Google Scholar</a>
        <span class="separator">•</span>
        <a target="_blank" href="https://twitter.com/Aniket_d98" class="social-link">Twitter</a>
        <span class="separator">•</span>
        <a target="_blank" href="https://github.com/dido1998/" class="social-link">Github</a>
      </div>
    </div>

    <div class="news-section">
      <h2>Recent News</h2>
      <div class="news-container">
        <ul>
          <li><b>Sep 2025</b>: Excited to release our new paper on <a target="_blank" href="https://arxiv.org/abs/2509.13237">LLM reasoning</a>, specifically a pipeline to enable efficient reasoning in thinking LLMs.</li>
          <li><b>Mar 2025</b>: Paper titled <a target="_blank" href="https://arxiv.org/abs/2503.21747">CTRL-O: Language-Controllable Object-Centric Visual Representation Learning</a> accepted at CVPR 2025.</li>
          <li><b>Jan 2025</b>: Paper titled <a target="_blank" href="https://arxiv.org/abs/2405.12205">On the Transfer of Object-Centric Representation Learning</a> accepted at ICLR 2025.</li>
          <li><b>Sep 2024</b>: Paper titled <a target="_blank" href="https://arxiv.org/abs/2405.12205">Metacognitive Capabilities of LLMs: An Exploration in Mathematical Problem Solving</a> accepted at NeurIPS 2024.</li>
          <li><b>Sep 2024</b>: I am excited to join <a target="_blank" href="https://ai.facebook.com/">Meta</a> as a research intern working with <a target="_blank" href="https://scholar.google.com/citations?user=ZWCcHYwAAAAJ" target="_blank">Dr. Nicolas Ballas</a>.</li>
          <li><b>July 2025</b>: New preprint out on <a target="_blank" href="https://arxiv.org/abs/2405.12205">general-purpose object-centric representation learning</a>.</li>
          <li><b>May 2024</b>: New preprint out on exploring the <a target="_blank" href="https://arxiv.org/abs/2405.12205">Metacognitive capabilities of LLMs</a>.</li>
          <li><b>Jan 2024</b>: Paper titled <a target="_blank" href="https://openreview.net/forum?id=f1xnBr4WD6">Cycle Consistency Driven Object Discovery</a> accepted at ICLR 2024.</li>
          <li><b>Dec 2023</b>: Awarded the <a target="_blank" href="https://www.unique.quebec/2024-unique-excellence-scholarships">Unique Excellence Scholarship</a> worth $15000 in support of my Ph.D. at Mila.</li>
          <li><b>June 2023</b>: Started as a machine learning intern at Recursion Pharmaceuticals/Valence Labs advised by Dr. Jason Hartford.</li>
          <li><b>May 2023</b>: Started Ph.D. at Mila and The University of Montreal advised by Prof. Yoshua Bengio and Dr. Anirudh Goyal.</li>
          <li><b>Sep 2022</b>: Our work <a target="_blank" href="https://arxiv.org/abs/2205.14794">Temporal Latent Bottleneck: Synthesis of Fast and Slow Processing Mechanisms in Sequence Learning</a> has been accepted to NeurIPS 2022!</li>
          <li><b>Aug 2022</b>: Joined Microsoft Research-NYC as a research intern!</li>
          <li><b>April 2022</b>: Awarded a scholarship worth $1500 by The University of Alberta and The <a target="_blank" href="https://www.amii.ca/">Alberta Machine Intelligence Institute</a> to visit Edmonton to attend the <a target="_blank" href="https://www.amii.ca/events/amii-presents-ai-week/">Amii AI week</a>.</li>
          <li><b>April 2022</b>: Awarded a scholarship worth $4000 by The University of Montreal and The Quebec Ministry of Higher Education.</li>
          <li><b>Jan 2022</b>: Our work <a target="_blank" href="https://openreview.net/forum?id=XzTtHjgPDsT">Coordination Among Neural Modules Through a Shared Global Workspace</a> has been accepted for <b>Oral presentation</b> at ICLR 2022.</li>
          <li><b>Oct 2021</b>: Our work <a target="_blank" href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/8f121ce07d74717e0b1f21d122e04521-Abstract-round2.html">Systematic Evaluation of Causal Discovery in Visual Model-Based RL</a> has been accepted at NeurIPS Dataset and Benchmark Track 2021.</li>
          <li><b>Sep 2021</b>: Our work <a target="_blank" href="https://openreview.net/forum?id=xQGYquca0gB">Neural Production Systems</a> has been accepted at NeurIPS 2021.</li>
          <li><b>Aug 2021</b>: Joined as a Research Master's Student at <a target="_blank" href="https://mila.quebec/">MILA</a></li>
          <li><b>Feb 2021</b>: Served in the program committee for <a target="_blank" href="https://2021.aclweb.org/">ACL-IJCNLP 2021</a>.</li>
          <li><b>Oct 2020:</b> Paper <a target="_blank" href="https://www.aclweb.org/anthology/2020.coling-main.611/">mixup for NLP</a> accepted at COLING 2020.</li>
          <li><b>Aug 2020:</b> Joined as a Research Intern at <a target="_blank" href="https://mila.quebec/">MILA</a>.</li>
          <li><b>July 2020:</b> Paper <a target="_blank" href="http://www.interspeech2020.org/index.php?m=content&c=index&a=show&catid=270&id=485">mixup for speech</a> accepted at Interspeech 2020.</li>
          <li><b>Jan 2020:</b> Started as Research Intern at <a target="_blank" href="https://www.iisc.ac.in/">IISC Bangalore</a>.</li>
          <li><b>May 2019:</b> Paper on <a target="_blank" href="https://www.aclweb.org/anthology/P19-2038/">arabic-hate speech profiling</a> accepted at ACL-SRW 2019.</li>
          <li><b>May 2019:</b> Joined as an intern at <a target="_blank" href="https://www.ubisoft.com/en-us/">Ubisoft India Studios</a>.</li>
          <li><b>May 2019:</b> Accepted into <a target="_blank" href="https://summerofcode.withgoogle.com/">Google Summer of Code 2019</a>.</li>
          <li><b>Apr 2019:</b> Joined as a research intern at <a target="_blank" href="http://midas.iiitd.edu.in/">MIDAS Lab</a>, IIIT Delhi.</li>
          <li><b>Apr 2019:</b> My paper for the <a target="_blank" href="https://reproducibility-challenge.github.io/iclr_2019/" target="_blank">ICLR Reproducibility Challenge 2019</a> was one of the 4 papers to be accepted to appear in the <a target="_blank" href="https://rescience.github.io/bibliography/Didolkar_2019.html">Journal of ReScience</a>.</li>
        </ul>
      </div>
    </div>

    <div class="research-section">
      <h2>Selected Publications (* = equal contribution)</h2>
    
      
      <div class="publications">
        <table style="width:120%;border:0px;border-spacing:20px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:30px;width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/metago_reuse.png' height="110" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Metacognitive Reuse: Turning Recurring LLM Reasoning Into Concise Behaviors</papertitle>
              <br>
              <b style="color:red;">Aniket Didolkar</b>,
              Nicolas Ballas,
              Sanjeev Arora,
              Anirudh Goyal
              <br>
             <b style="color:orange">Preprint</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2509.13237">Paper</a>
              <p></p>
              <p>A pipeline to convert recurring reasoning patterns into concise behaviors for improved and efficient LLM reasoning.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:30px;width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/skills.png' height="110" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Metacognitive Capabilities of LLMs: An Exploration in Mathematical Problem Solving</papertitle>
              <br>
              <b style="color:red;">Aniket Didolkar</b>,
              Anirudh Goyal,
              Nan Rosemary Ke,
              Siyuan Guo,
              Michal Valko,
              Timothy Lillicrap,
              Danilo Rezende,
              Yoshua Bengio,
              Michael Mozer,
              Sanjeev Arora
              <br>
              <b style="color:orange">NeurIPS 2024</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2405.12205">Paper</a>
              <p></p>
              <p>Probing the metacognitive capabilities of LLMs to improve mathematical problem solving.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:30px;width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/ctrlo.png' height="110" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>CTRL-O: Language-Controllable Object-Centric Visual Representation Learning</papertitle>
              <br>
              <b style="color:red;">Aniket Didolkar*</b>,
              Andrii Zadaianchuk*,
              Rabiul Awal*,
              Maximilian Seitzer,
              Efstratios Gavves,
              Aishwarya Agrawal
              <br>
              <b style="color:orange">CVPR 2025</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2503.21747">Paper</a> /
              <a target="_blank" href="https://ctrl-o-paper.github.io/">Project Page</a> /
              <a target="_blank" href="https://github.com/dido1998/CTRL-O">Code</a>
              <p></p>
              <p>User-controllable visual representation learning.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:30px;width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/zero-shot.png' height="110" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>On the Transfer of Object-Centric Representation Learning</papertitle>
              <br>
              <b style="color:red;">Aniket Didolkar*</b>, 
              Andrii Zadaianchuk,
              Anirudh Goyal,
              Michael Curtis Mozer,
              Yoshua Bengio,
              Georg Martius,
              Maximilian Seitzer*
              <br>
              <b style="color:orange">ICLR 2024</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2306.02204">Paper</a> /
              <a target="_blank" href="https://github.com/rw-ocrl/ftdinosaur-inference">Code</a> /
              <a target="_blank" href="https://rw-ocrl.github.io/ftdinosaur-paper/">Project Page</a>
              <p></p>
              <p>Building object-centric models from a foundation model perspective.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:30px;width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/cycle_consistency.png' height="110" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Cycle Consistency Driven Object Discovery</papertitle>
              <br>
              <b style="color:red;">Aniket Didolkar</b>,
              Anirudh Goyal,
              Yoshua Bengio
              <br>
              <b style="color:orange">ICLR 2024</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2306.02204">Paper</a>
              <p></p>
              <p>Unsupervised Object-Discovery via two cycle-consistency objectives.
              </p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:30px;width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/tlb.png' height="130" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Temporal Latent Bottleneck: Synthesis of Fast and Slow Processing Mechanisms in Sequence Learning</papertitle>
              <br>
              <b style="color:red;">Aniket Didolkar</b>,
              Kshitij Gupta,
              Anirudh Goyal,
              Alex Lamb,
              Nan Rosemary Ke,
              Yoshua Bengio
              <br>
              <b style="color:orange">NeurIPS, 2022</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2205.14794">Paper</a> / <a target="_blank" href="https://docs.google.com/presentation/d/1HD1b81C9IcuzWozwC5FmUSSc_2jjvfPNFKfeygl1040/edit?usp=sharing">slides</a>
              <p></p>
              <p>Merging transformers with recurrent networks to effectively handle long-context tasks.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:30px;width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/acstate.png' height="130" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Guaranteed Discovery of Controllable Latent States with Multi-Step Inverse Models</papertitle>
              <br>
              Alex Lamb,
              Riashat Islam,
              Yonathan Efroni,
              <b style="color:red;">Aniket Didolkar</b>,
              Dipendra Misra,
              Dylan Foster,
              Lekan Molu,
              Rajan Chari,
              Akshay Krishnamurthy,
              John Langford,
              <br>
              <b style="color:orange">TMLR 2023</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2207.08229">Paper</a>
              <p></p>
              <p>Algorithm for discovery of the minimal controllable latent state that has all the information for controlling an agent while learning to discard all other irrelevant information.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:30px;width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/sw.png' height="130" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Coordination Among Neural Modules Through a Shared Global Workspace</papertitle>
              <br>
              Anirudh Goyal,
              <b style="color:red;">Aniket Didolkar</b>,
              Alex Lamb,
              Kartikeya Badola,
              Nan Rosemary Ke,
              Nasim Rahaman,
              Jonathan Binas,
              Charles Blundell,
              Michael Mozer,
              Yoshua Bengio
              <br>
              <b style="color:orange">ICLR, 2022</b> <b style="color:darkred;">(Oral Presentation - top 5% of accepted paper)</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2103.01197">Paper</a>
              <p></p>
              <p>Facilitating communication between modules using a limited-capacity bottleneck.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/nps.png' width="200" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Neural Production Systems</papertitle>
              <br>
              <b style="color:red;">Aniket Didolkar*</b>,
              Anirudh Goyal*,
              Nan Rosemary Ke,
              Charles Blundell,
              Philippe Beaudoin,
              Nicolas Heess,
              Michael Mozer,
              Yoshua Bengio
              <br>
              <b style="color:orange">NeurIPS, 2021</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2103.01937">Paper</a> 
              <p></p>
              <p>World models via sparsely communicating recurrent modules.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/systematic.png' height="130" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Systematic Evaluation of Causal Discovery for Visual Model Based Reinforcement Learning</papertitle>
              <br>
              Nan Rosemary Ke*,
              <b style="color:red;">Aniket Didolkar*</b>,
              Sarthak Mittal,
              Anirudh Goyal,
              Guillaume Lajoie,
              Stefan Bauer,
              Danilo Rezende,
              Yoshua Bengio,
              Michael Mozer,
              Christopher Pal
              <br>
              <b style="color:orange">NeurIPS Dataset and Benchmark Track, 2021</b>
              <br>
              <a target="_blank" href="https://arxiv.org/abs/2107.00848">Paper</a> /
              <a target="_blank" href="https://github.com/dido1998/CausalMBRL">Code</a>
              <p></p>
              <p>A new and highly-flexible benchmark for evaluation of causal discovery in model-based RL.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/nlp_mixup.png' height="130" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Augmenting NLP models using Latent Feature Interpolations</papertitle>
              <br>
              Amit Jindal,
              <b style="color:red;">Aniket Didolkar</b>,
              Arijit Ghosh Chowdhury,
              Ramit Sawhney,
              Rajiv Ratn Shah,
              Di Jin
              <br>
              <b style="color:orange">Coling, 2020</b>
              <br>
              <a target="_blank" href="https://aclanthology.org/2020.coling-main.611.pdf">Paper</a>
              <p></p>
              <p>Proposed a new formulation of mixup for NLP.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/speechmix.png' height="130" width="220">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>SpeechMix - Augmenting Deep Sound Recognition using Hidden Space Interpolations</papertitle>
              <br>
              Amit Jindal, Narayanan Elavathur, Ranganatha, <b style="color:red;">Aniket Didolkar</b>, Arijit Ghosh Chowdhury, Ramit Sawhney, Rajiv Ratn Shah, Di Jin
              <br>
              <b style="color:orange">Interspeech, 2020</b>
              <br>
              <a target="_blank" href="https://indico2.conference4me.psnc.pl/event/35/contributions/2910/attachments/559/586/Mon-2-8-10.pdf">Paper</a>
              <p></p>
              <p>Data augmentation using mixup for speech.
              </p>
            </td>
          </tr>
        </tbody></table>
      </div>
    </div>
  </div>
</body>
</html>
